{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash Function\n",
    "\n",
    "Imagine representing natural numbers as a strings. One we use everyday is base 10. Let's call it decimal encoding. \n",
    "\n",
    "All of the items in the *domain* **maps** to a unique element in the *range* set. i.e one-to-one mapping.\n",
    "\n",
    "Alphabet for decimal encoding is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\Sigma = \\{0, 1, 2 .. , 9\\}$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$\\Sigma = \\{0, 1, 2 .. , 9\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transition function for decimal **encoding** is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\delta(Q) = \\{ \n",
       "    (\\text{item}[0] \\times 10^0)\\:+ \n",
       "    (\\text{item}[1] \\times 10^1)\\:+ \n",
       "    \\:...\\: + \n",
       "    ( \\text{item}[i] \\times 10^i )\\:+\\:...\\:\\} \n",
       "\\quad \\text{where} \\: item \\in \\Sigma \n",
       "    \\: \\text{and} \\: 0 < i < \\mid Q \\mid$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$\\delta(Q) = \\{ \n",
    "    (\\text{item}[0] \\times 10^0)\\:+ \n",
    "    (\\text{item}[1] \\times 10^1)\\:+ \n",
    "    \\:...\\: + \n",
    "    ( \\text{item}[i] \\times 10^i )\\:+\\:...\\:\\} \n",
    "\\quad \\text{where} \\: item \\in \\Sigma \n",
    "    \\: \\text{and} \\: 0 < i < \\mid Q \\mid$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the same idea on a larger alphabet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\Sigma = \\{0, 1, 2, .. 9 ,a, b, ... z, A, B, ...\\}$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$\\Sigma = \\{0, 1, 2, .. 9 ,a, b, ... z, A, B, ...\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the idea above to convert any string to an integer. This approach has two problems.\n",
    "\n",
    "Given alphabet size n and string length m, we will have to represent n^m size integers.\n",
    "\n",
    "### Direct Access Tables\n",
    "\n",
    "One way to implement this is to convert input keys into memory locations.\n",
    "\n",
    "Problem with this is that it will require memory of n^m size. \n",
    "\n",
    "Now instead of one-to-one mapping, let's try to reduce the size of the result set to fit in our memory. This is an acceptable solution in an ideal world where we receive uniformly distributed keys sequentially.\n",
    "\n",
    "We will be slightly modifying our **encoding** function.\n",
    "\n",
    "One solution to reduce the dimension is to just take the modulus of the key. \n",
    "\n",
    "### Collision\n",
    "\n",
    "Due to pigeon hole principle, given a large input set(domain or keys) completely mapping on to a smaller output set(range, \\delta of key) some items will overlap.\n",
    "\n",
    "### Chaining\n",
    "Strategy where upon collisions, items are inserted to the end of a linked list starting from that slot.\n",
    "\n",
    "Assume uniform hashing where each key is equally likely to be hashed to any slot of the table independent of where other keys hash.\n",
    "\n",
    "Given this assumption, let's try to find the expected length of the linked lists at the slot.\n",
    "\n",
    "For n keys, mapping on to m slots, we expect probability of insertion to a particular slot to be 1/m. Then, inserting into slots n times should yield to a total n/m. This is denoted by alpha and is also known as the load factor.\n",
    "\n",
    "Load factor of n = m is 1. Then the list lengths are 1, hence lookup time is O(1).\n",
    "\n",
    "Running time is O(1 + n/m).\n",
    "\n",
    "### Hashing\n",
    "\n",
    "Hashing is chopping things into pieces. \n",
    "\n",
    "#### Division method\n",
    "\n",
    "h(k) = k mod m\n",
    "This method is bad especially if k and m have common factors. It's good if it's nopt close to power of 10 and 2.\n",
    "\n",
    "#### Multiplication Method\n",
    "h(k) = \\[a * k mod 2^w\\] >> (w-r)\n",
    "\n",
    "say k is w bits and r is log(CAPACITY)\n",
    "\n",
    "#### Universal Hashing\n",
    "h(k) = \\[(ak + b) mod p\\] mod m\n",
    "\n",
    "large prime p and random a and b < p -1\n",
    "\n",
    "For worst case keys where k1 != k2\n",
    "\n",
    "Pr {h(k1) = h(k2}} = 1/m\n",
    "\n",
    "Probability over choice of a and b. If you can randomly choose a and b\n",
    "\n",
    "Expected number of collistions with k1 = Expected\\[Total over k2(X k1 k2)\\] = Total over K2 Expected\\[X k1 k2\\] = total \\[Probablity X k1 k2 = 1\\]\n",
    "\n",
    "Given that Pr(x k1 k2) is 1/m\n",
    "\n",
    "= n/m = \\alpha -> load factor \n",
    "\n",
    "### Rehashing\n",
    "\n",
    "Grow the table when number of elements we try to insert to the hash is larger than the slots available.\n",
    "\n",
    "Build a new hash function. Iterate through the table and list if required(using chaining).\n",
    "\n",
    "Choose a growth rate of m' = m + 1. Then, starting from a table of size 1, the total cost of insertion for a table to reach the size m':\n",
    "\n",
    "\\Theta(1 + 2 + .. + n) = \\Theta(n^2)\n",
    "\n",
    "Growht m' = 2m -> Table doubling.\n",
    "\n",
    "1st cost to rebuild is constant\n",
    "2nd 2 \n",
    "3 -> 4\n",
    "\n",
    "\\Theta(1 + 2 + 4 + 8 + ... + n) = \\Theta(n)\n",
    "\n",
    "Even though this looks in the first glance that insertion will take linear time, rehashing will happen only on occasion. \n",
    "\n",
    "If we can describe this behaivor over a sequence of operations we will find the avarage complexity.\n",
    "\n",
    "#### Amortization\n",
    "\n",
    "This concept makes sense for data structures. \n",
    "\n",
    "For k inserts, single insertion then will take \\Theta(n)/m = \\Theta(1)\n",
    "\n",
    "#### Deletion - Shrinking\n",
    "\n",
    "Given table doubling for growth function, we can't use m/2 for load factor. If we do it is O(n) because circling between insertion and deletion around m/2 will rehash for every operation.\n",
    "\n",
    "list.append and list.pop is O(1) amortized.\n",
    "\n",
    "One implementation for O(1) worst-case is to start creating a table double the size on the side, move elements at a constant rate(5 of them at a time) until table is full and just switch once it is.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
